{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    h2, h4, h6 { \n",
       "        margin: 0;\n",
       "        font-family: serif;\n",
       "    }\n",
       "    p {\n",
       "    font-family: serif;\n",
       "    }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSS for the markdown cells\n",
    "mycss = \"\"\"\n",
    "    h2, h4, h6 { \n",
    "        margin: 0;\n",
    "        font-family: serif;\n",
    "    }\n",
    "    p {\n",
    "    font-family: serif;\n",
    "    }\n",
    "\"\"\"\n",
    "from IPython.core.display import display, HTML\n",
    "HTML('<style>{}</style>'.format(mycss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>(Special) Collections as Data</h3>\n",
    "<h4>Part 2 of 3</h4>\n",
    "<h6>See Part One of this project [here](https://).</h6></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This notebook steps through the process of cleaning up the MARC data from Part One, with the aim of reducing the number of columns (through concatenation) to a manageable amount for analysis and visualization. <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the pandas library/module\n",
    "import pandas as pd\n",
    "# load the groupby function\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading our data\n",
    "data = pd.read_pickle('../path/to/your/files/here/all_spec_single_fields.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['008_date1', '008_date2', '008_lang', '041-0_-a', '041-0_-h',\n",
       "       '041-1_-a', '041-1_-h', '041-_1-a', '041-_1-h', '041-_7-a',\n",
       "       ...\n",
       "       '260-__-f', '260-__-g', '300-__-a', '300-__-b', '300-__-c', '752-__',\n",
       "       'bib_id', 'normalized_call_no', 'display_call_no', 'location_code'],\n",
       "      dtype='object', length=120)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are now a lot of columns, because of all the field-subfield-indicator combinations\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The code below lets us print all the columns for ease of reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort the columns by the MARC field, excluding those from the 008 and those that aren't MARC fields \n",
    "columns = sorted(data.columns[3:-4], key=lambda x: x.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group the list by the first element in each item (the MARC field tag)\n",
    "g = groupby(columns, key=lambda x: x.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary, with the key as the grouper and the value as a list of all things in that group\n",
    "d = {gg[0]: list(gg[1]) for gg in g}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the grouped list and print with a visual separator between each field\n",
    "for k,v in d.items():\n",
    "    print(k)\n",
    "    print('\\n'.join(v))\n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to rename the columns from the original MARC extract, concatenating where it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename columns from the original dataframe\n",
    "new_columns = {'041-1_-a': 'translation_languages',\n",
    "              '041-0_-a': 'additional_languages',\n",
    "              '041-1_-h': 'original_language',\n",
    "              '041-__-a': 'additional_languages',\n",
    "              '041-__-h': 'original_language',\n",
    "              '100-0_-a': 'mono_author_name',\n",
    "              '100-10-a': 'author_name',\n",
    "              '100-1_-a': 'author_name',\n",
    "              '100-20-a': 'author_name',\n",
    "                '100-2_-a': 'author_name',\n",
    "               '100-3_-a': 'author_name_family',\n",
    "               '752-__': 'added_place',\n",
    "               '300-__-a': 'extent',\n",
    "               '300-__-b': 'other_physical_details',\n",
    "               '300-__-c': 'dimensions'\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of information in the 245 we don't care about (having to do with character offsets, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For renaming the 245 subfields\n",
    "title = {'a': 'title', \n",
    "         'b': 'remainder_of_title', \n",
    "         'c': 'statement_of_responsibility'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a reverse list of columns, assigning the MARC fields to the labels we want to use\n",
    "column_map = {}\n",
    "for k,v in new_columns.items():\n",
    "    if v in column_map:\n",
    "        column_map[v].append(k)\n",
    "    else:\n",
    "        column_map[v] = [k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where there are nulls in the data, pandas add a **NaN** element by default. But converting that to the empty string means that we can treat all cells as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we populate our new DataFrame with concatenated versions of the columns from the original extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cleaned = pd.DataFrame()\n",
    "for k, v in column_map.items():\n",
    "    # For each column in the target DataFrame, combine the values from the corresponding columns in the source DataFrame\n",
    "    # We're using the pipe character as a separator because that probably doesn't appear in any of the MARC data\n",
    "    # On the right side of this assignment, we're taking advantage of the fact that pandas allows us to select multiple columns of a DataFrame by passing it a list\n",
    "    data_cleaned[k] = data[v].apply(lambda x: ' | '.join([s for s in x if s]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The 245 field is a simpler matter -- we can ignore the indicators altogether!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_fields = [c for c in data.columns if c.startswith('245')]\n",
    "for k, v in title.items():\n",
    "    data_cleaned[v] = data[[c for c in title_fields if c.endswith(k)]].apply(lambda x: ' | '.join([s for s in x if s]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new DataFrame needs the first three and the last four columns from the original. (Because we were concatenating along the columns access, both frames should have the same number of rows, and we have preserved the order, so we can simply \"stick\" those columns onto the new DF, as it were.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cleaned[data.columns[:3]] = data[data.columns[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cleaned[data.columns[-4:]] = data[data.columns[-4:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure to save your work!\n",
    "data_cleaned.to_pickle('..path/to/your/files/here/all_spec_single_fields_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Normalizing the Publication Year (008 Field) **\n",
    "\n",
    "This function will change nulls and non-digit characters to digits. We're using zero to fill in for the \"u\" character in the MARC data (\"u\"=\"unknown\"). Depending on the kind of analysis you want to do, this may or may not be desirable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_yr(year):\n",
    "    if year.isspace():\n",
    "        year = '9999'\n",
    "    elif year == '||||':\n",
    "        year = '9999'\n",
    "    else:\n",
    "        year = year.replace('u', '0')\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cleaned['008_date1'] = data_cleaned['008_date1'].apply(convert_yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the century, just take the first two characters from each pub year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note the .str on the end of the right-hand side of the equation. \n",
    "# That tells pandas that we want to perform the slice on the string values themselves from each element in this column\n",
    "# Otherwise, pandas will try to take the first two elements of the column, which is not what we want\n",
    "data_cleaned['century'] = data_cleaned['008_date1'].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_cleaned.to_pickle('..path/to/your/files/here/all_spec_single_fields_cleaned.pkl')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
